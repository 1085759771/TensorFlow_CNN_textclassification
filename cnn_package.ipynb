{"cells": [{"metadata": {"trusted": true}, "cell_type": "code", "source": "from sklearn.model_selection import train_test_split\nimport pickle\nfrom collections import Counter\nimport tensorflow.contrib.keras as kr\nfrom sklearn.preprocessing import LabelEncoder\nimport tensorflow as tf\nimport random\nimport numpy as np\nimport pandas as pd\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import precision_recall_fscore_support\nimport warnings\nwarnings.filterwarnings('ignore')\nimport time\n\nclass TextConfig():\n    vocab_size = 24000\n    seq_length = 600\n    embedding_dim = 64  # \u8bcd\u5411\u91cf\u7ef4\u5ea6\n    num_filters = 256  # \u5377\u79ef\u6838\u6570\u76ee\n    kernel_size = 5  # \u5377\u79ef\u6838\u5c3a\n    hidden_dim = 128  # \u5168\u8fde\u63a5\u5c42\u795e\u7ecf\u5143\n    dropout_keep_prob = 0.5  # dropout\u4fdd\u7559\u6bd4\u4f8b\n    learning_rate = 1e-3  # \u5b66\u4e60\u7387\n    batch_size = 32  # \u6bcf\u6279\u8bad\u7ec3\u5927\u5c0f\n    num_iteration = 5000 #\u8fed\u4ee3\u6b21\u6570\n    print_per_batch = num_iteration / 20 #\u6253\u5370\u95f4\u9694\n\nclass TextClassification():\n    def config(self):\n        textConfig = TextConfig()\n        self.vocab_size = textConfig.vocab_size\n        self.seq_length = textConfig.seq_length\n        self.embedding_dim = textConfig.embedding_dim\n        self.num_filters = textConfig.num_filters\n        self.kernel_size = textConfig.kernel_size\n        self.hidden_dim = textConfig.hidden_dim\n        self.dropout_keep_prob = textConfig.dropout_keep_prob\n        self.learning_rate = textConfig.learning_rate\n        self.batch_size = textConfig.batch_size\n        self.print_per_batch = textConfig.print_per_batch\n        self.num_iteration = textConfig.num_iteration\n    \n    def __init__(self, *args):\n        self.config()\n        if len(args) == 2:\n            content_list = args[0]\n            label_list = args[1]\n            train_X, test_X, train_y, test_y = train_test_split(content_list, label_list)\n            self.train_content_list = train_X\n            self.train_label_list = train_y\n            self.test_content_list = test_X\n            self.test_label_list = test_y\n            self.content_list = self.train_content_list + self.test_content_list\n        elif len(args) == 4:\n            self.train_content_list = args[0]\n            self.train_label_list = args[1]\n            self.test_content_list = args[2]\n            self.test_label_list = args[3]\n            self.content_list = self.train_content_list + self.test_content_list\n        else:\n            print('false to init TextClassification object')\n        self.autoGetNumClasses()\n    \n    def autoGetNumClasses(self):\n        label_list = self.train_label_list + self.test_label_list\n        self.num_classes = np.unique(label_list).shape[0]\n    \n    def getVocabularyList(self, content_list, vocabulary_size):\n        allContent_str = ''.join(content_list)\n        counter = Counter(allContent_str)\n        vocabulary_list = [k[0] for k in counter.most_common(vocabulary_size)]\n        return ['PAD'] + vocabulary_list\n\n    def prepareData(self):\n        vocabulary_list = self.getVocabularyList(self.content_list, self.vocab_size)\n        if len(vocabulary_list) < self.vocab_size:\n            self.vocab_size = len(vocabulary_list)\n        contentLength_list = [len(k) for k in self.train_content_list]\n        if max(contentLength_list) < self.seq_length:\n            self.seq_length = max(contentLength_list)\n        self.word2id_dict = dict([(b, a) for a, b in enumerate(vocabulary_list)])\n        self.labelEncoder = LabelEncoder()\n        self.labelEncoder.fit(self.train_label_list)\n\n    def content2idList(self, content):\n        return [self.word2id_dict[word] for word in content if word in self.word2id_dict]\n\n    def content2X(self, content_list):\n        idlist_list = [self.content2idList(content) for content in content_list]\n        X = kr.preprocessing.sequence.pad_sequences(idlist_list, self.seq_length)\n        return X\n\n    def label2Y(self, label_list):\n        y = self.labelEncoder.transform(label_list)\n        Y = kr.utils.to_categorical(y, self.num_classes)\n        return Y\n\n    def buildModel(self):\n        tf.reset_default_graph()\n        self.X_holder = tf.placeholder(tf.int32, [None, self.seq_length])\n        self.Y_holder = tf.placeholder(tf.float32, [None, self.num_classes])\n        embedding = tf.get_variable('embedding', [self.vocab_size, self.embedding_dim])\n        embedding_inputs = tf.nn.embedding_lookup(embedding, self.X_holder)\n        conv = tf.layers.conv1d(embedding_inputs, self.num_filters, self.kernel_size)\n        max_pooling = tf.reduce_max(conv, reduction_indices=[1])\n        full_connect = tf.layers.dense(max_pooling, self.hidden_dim)\n        full_connect_dropout = tf.contrib.layers.dropout(full_connect, keep_prob=self.dropout_keep_prob)\n        full_connect_activate = tf.nn.relu(full_connect_dropout)\n        softmax_before = tf.layers.dense(full_connect_activate, self.num_classes)\n        self.predict_Y = tf.nn.softmax(softmax_before)\n        cross_entropy = tf.nn.softmax_cross_entropy_with_logits_v2(labels=self.Y_holder, logits=softmax_before)\n        self.loss = tf.reduce_mean(cross_entropy)\n        optimizer = tf.train.AdamOptimizer(self.learning_rate)\n        self.train = optimizer.minimize(self.loss)\n        self.predict_y = tf.argmax(self.predict_Y, 1)\n        isCorrect = tf.equal(tf.argmax(self.Y_holder, 1), self.predict_y)\n        self.accuracy = tf.reduce_mean(tf.cast(isCorrect, tf.float32))\n\n    def trainModel(self):\n        self.prepareData()\n        self.buildModel()\n        init = tf.global_variables_initializer()\n        self.session = tf.Session()\n        self.session.run(init)\n        train_X = self.content2X(self.train_content_list)\n        train_Y = self.label2Y(self.train_label_list)\n        test_X = self.content2X(self.test_content_list)\n        test_Y = self.label2Y(self.test_label_list)\n        startTime = time.time()\n        for i in range(self.num_iteration):\n            selected_index = random.sample(list(range(len(train_Y))), k=self.batch_size)\n            batch_X = train_X[selected_index]\n            batch_Y = train_Y[selected_index]\n            self.session.run(self.train, {self.X_holder: batch_X, self.Y_holder: batch_Y})\n            step = i + 1\n            if step % self.print_per_batch == 0 or step == 1:\n#                 print(len(train_Y))\n                selected_index = random.sample(list(range(len(test_Y))), k=200)\n                batch_X = test_X[selected_index]\n                batch_Y = test_Y[selected_index]\n                loss_value, accuracy_value = self.session.run([self.loss, self.accuracy],\\\n                    {self.X_holder: batch_X, self.Y_holder: batch_Y})\n                used_time = time.time() - startTime\n                print('step:%d loss:%.4f accuracy:%.4f used time:%.2f seconds' %\n                      (step, loss_value, accuracy_value, used_time))\n\n    def predict(self, content_list):\n        if type(content_list) == str:\n            content_list = [content_list]\n        batch_X = self.content2X(content_list)\n        predict_y = self.session.run(self.predict_y, {self.X_holder:batch_X})\n        predict_label_list = self.labelEncoder.inverse_transform(predict_y)\n        return predict_label_list\n\n    def predictAll(self):\n        predict_label_list = []\n        batch_size = 100\n        for i in range(0, len(self.test_content_list), batch_size):\n            content_list = self.test_content_list[i: i + batch_size]\n            predict_label = self.predict(content_list)\n            predict_label_list.extend(predict_label)\n        return predict_label_list\n\n    def printConfusionMatrix(self):\n        predict_label_list = self.predictAll()\n        df = pd.DataFrame(confusion_matrix(self.test_label_list, predict_label_list),\n                     columns=self.labelEncoder.classes_,\n                     index=self.labelEncoder.classes_)\n        print('\\n Confusion Matrix:')\n        print(df)\n\n    def printReportTable(self):\n        predict_label_list = self.predictAll()\n        reportTable = self.eval_model(self.test_label_list,\n                                 predict_label_list,\n                                 self.labelEncoder.classes_)\n        print('\\n Report Table:')\n        print(reportTable)\n        \n    def eval_model(self, y_true, y_pred, labels):\n        # \u8ba1\u7b97\u6bcf\u4e2a\u5206\u7c7b\u7684Precision, Recall, f1, support\n        p, r, f1, s = precision_recall_fscore_support(y_true, y_pred)\n        # \u8ba1\u7b97\u603b\u4f53\u7684\u5e73\u5747Precision, Recall, f1, support\n        tot_p = np.average(p, weights=s)\n        tot_r = np.average(r, weights=s)\n        tot_f1 = np.average(f1, weights=s)\n        tot_s = np.sum(s)\n        res1 = pd.DataFrame({\n            u'Label': labels,\n            u'Precision': p,\n            u'Recall': r,\n            u'F1': f1,\n            u'Support': s\n        })\n        res2 = pd.DataFrame({\n            u'Label': ['\u603b\u4f53'],\n            u'Precision': [tot_p],\n            u'Recall': [tot_r],\n            u'F1': [tot_f1],\n            u'Support': [tot_s]\n        })\n        res2.index = [999]\n        res = pd.concat([res1, res2])\n        return res[['Label', 'Precision', 'Recall', 'F1', 'Support']]", "execution_count": 8, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "import pickle\nimport moxing.tensorflow as mox\nimport os\n\n# data_url = 's3://vivizhao-textclsf/data/'\n# local_url = './'\n# mox.file.copy_parallel(data_url, local_url)\n\nwith open('train_content_list.pickle', 'rb') as file:\n    train_content_list = pickle.load(file)\nwith open('train_label_list.pickle', 'rb') as file:\n    train_label_list = pickle.load(file)\nwith open('test_content_list.pickle', 'rb') as file:\n    test_content_list = pickle.load(file)\nwith open('test_label_list.pickle', 'rb') as file:\n    test_label_list = pickle.load(file)\n    ", "execution_count": 2, "outputs": [{"output_type": "stream", "text": "INFO:root:Using MoXing-v1.13.0-04f86dc7\nINFO:root:Using OBS-Python-SDK-3.1.2\nINFO:tensorflow:Using TensorFlow-v1.8.0-0-g93bc2e2072\n", "name": "stderr"}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "model = TextClassification(train_content_list,\n                           train_label_list,\n                           test_content_list,\n                           test_label_list)\nmodel.trainModel()\nmodel.printConfusionMatrix()\nmodel.printReportTable()", "execution_count": 9, "outputs": [{"output_type": "stream", "text": "step:1 loss:2.4888 accuracy:0.0550 used time:0.92 seconds\nstep:250 loss:0.6485 accuracy:0.8050 used time:115.32 seconds\nstep:500 loss:0.3738 accuracy:0.8950 used time:231.12 seconds\nstep:750 loss:0.3408 accuracy:0.8950 used time:345.93 seconds\nstep:1000 loss:0.1836 accuracy:0.9300 used time:461.22 seconds\nstep:1250 loss:0.2093 accuracy:0.9350 used time:577.02 seconds\nstep:1500 loss:0.2693 accuracy:0.9250 used time:693.52 seconds\nstep:1750 loss:0.1990 accuracy:0.9600 used time:807.52 seconds\nstep:2000 loss:0.2087 accuracy:0.9450 used time:922.22 seconds\nstep:2250 loss:0.1611 accuracy:0.9350 used time:1037.63 seconds\nstep:4750 loss:0.2015 accuracy:0.9700 used time:2202.72 seconds\nstep:5000 loss:0.3601 accuracy:0.9450 used time:2320.32 seconds\n\n Confusion Matrix:\n      \u4f53\u80b2   \u5065\u5eb7   \u5973\u4eba   \u5a31\u4e50  \u623f\u5730\u4ea7   \u6559\u80b2   \u6587\u5316   \u65b0\u95fb   \u65c5\u6e38   \u6c7d\u8f66   \u79d1\u6280   \u8d22\u7ecf\n\u4f53\u80b2   992    0    1    1    0    1    0    2    0    0    2    1\n\u5065\u5eb7     2  964    5    0    2    5    1   15    0    1    2    3\n\u5973\u4eba     0    3  963    3    0    7   15    1    1    2    4    1\n\u5a31\u4e50     2    2    0  959    0    1   18    5    1    3    8    1\n\u623f\u5730\u4ea7    0    0    0    0  906    3    7   42    3    5    5   29\n\u6559\u80b2     1    0    0    1    1  968    5   13    2    1    4    4\n\u6587\u5316     0    0    4    5    8    4  935   25    3    7    9    0\n\u65b0\u95fb     4    2    0    0   10    9   13  934    4    3    7   14\n\u65c5\u6e38     3    1    1    0   15    3   11   12  932    7    8    7\n\u6c7d\u8f66     5    0    0    0    0    1    0    4    2  984    3    1\n\u79d1\u6280     1    0    1    0    2    0    3   17    0    0  963   13\n\u8d22\u7ecf     0    1    0    0    6    0    1   17    2    3   11  959\n\n Report Table:\n    Label  Precision    Recall        F1  Support\n0      \u4f53\u80b2   0.982143  0.990000  0.986056     1000\n1      \u5065\u5eb7   0.994840  0.964000  0.979177     1000\n2      \u5973\u4eba   0.984631  0.961000  0.972672     1000\n3      \u5a31\u4e50   0.988695  0.962000  0.975165     1000\n4     \u623f\u5730\u4ea7   0.951731  0.907000  0.928827     1000\n5      \u6559\u80b2   0.964250  0.971000  0.967613     1000\n6      \u6587\u5316   0.931615  0.940000  0.935789     1000\n7      \u65b0\u95fb   0.865865  0.936000  0.899568     1000\n8      \u65c5\u6e38   0.979101  0.937000  0.957588     1000\n9      \u6c7d\u8f66   0.967520  0.983000  0.975198     1000\n10     \u79d1\u6280   0.942495  0.967000  0.954590     1000\n11     \u8d22\u7ecf   0.935610  0.959000  0.947160     1000\n999    \u603b\u4f53   0.957375  0.956417  0.956617    12000\n", "name": "stdout"}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "# model = TextClassification(train_content_list,\n#                            train_label_list,\n#                            test_content_list,\n#                            test_label_list)\nnews = ''\nwith open('news.txt', 'r') as file:\n    for lines in file:\n        news+=lines\nresultlist = model.predict(news)\nprint(resultlist)", "execution_count": 11, "outputs": [{"output_type": "stream", "text": "['\u6587\u5316']\n", "name": "stdout"}]}], "metadata": {"kernelspec": {"name": "tensorflow-1.8", "display_name": "TensorFlow-1.8", "language": "python"}, "language_info": {"name": "python", "version": "3.6.4", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat": 4, "nbformat_minor": 2}